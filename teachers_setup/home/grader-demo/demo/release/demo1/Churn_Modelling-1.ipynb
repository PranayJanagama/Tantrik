{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995f5b40",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bca596",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb9499-82d7-4486-87ae-054cca1a950f",
   "metadata": {
    "id": "8fcb9499-82d7-4486-87ae-054cca1a950f"
   },
   "source": [
    "You are tasked with creating a simple artificial neural network (ANN) from scratch\n",
    "\n",
    "1. Setup the Environment\n",
    "Import necessary libraries\n",
    "Load the dataset\n",
    "2. Data Preprocessing\n",
    "Normalize the data\n",
    "Split the data into training and testing sets\n",
    "3. Define the ANN from Scratch\n",
    "Initialize parameters\n",
    "Define the activation function (e.g., ReLU, Sigmoid)\n",
    "Implement forward propagation\n",
    "Implement the cost function (e.g., Cross-Entropy Loss)\n",
    "Implement backward propagation\n",
    "Implement the update rule (Gradient Descent)\n",
    "Compile the model\n",
    "4. Training the Model\n",
    "Implement a training loop\n",
    "Track and print the loss over epochs\n",
    "5. Evaluation\n",
    "Implement a function to evaluate accuracy on the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37473621-3c29-4acb-b059-18ab50a5a448",
   "metadata": {
    "id": "37473621-3c29-4acb-b059-18ab50a5a448"
   },
   "source": [
    "# Step 1 Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c08c19-3cf0-4f38-8e52-de262dec4e4f",
   "metadata": {
    "deletable": false,
    "id": "d2c08c19-3cf0-4f38-8e52-de262dec4e4f",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "090903aede3d5d61248ae2c173364615",
     "grade": false,
     "grade_id": "cell-f5d34c715e1b0fbc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0daf210-3c05-48f4-8851-f16183fac7ca",
   "metadata": {
    "id": "c0daf210-3c05-48f4-8851-f16183fac7ca"
   },
   "source": [
    "# Step 2 Load the dataset ,Select dependent and Independent variable X,y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6867c6d1-e18a-4d59-ab3e-0e4cb206d377",
   "metadata": {
    "id": "6867c6d1-e18a-4d59-ab3e-0e4cb206d377"
   },
   "source": [
    "You are provided with a dataset named Churn_Modelling.csv, which contains various features related to customers of a company. Your goal is to load this dataset, separate the features from the target variable, and prepare them for training ANN model.\n",
    "\n",
    "Task:\n",
    "Load the Dataset:\n",
    "\n",
    "Use the pandas library to load the Churn_Modelling.csv file into a DataFrame.\n",
    "Prepare Features (X):\n",
    "\n",
    "Drop the Exited column from the DataFrame, as it is the target variable.\n",
    "Convert the remaining data into a NumPy array. This will serve as the feature set X.\n",
    "Prepare Target (y):\n",
    "\n",
    "Extract the Exited column from the DataFrame.\n",
    "Convert it into a NumPy array and reshape it to ensure it has the correct shape for machine learning algorithms (i.e., a column vector with one output per row).\n",
    "Csv file path : /srv/shareddata/datasets/ps2/Churn_Modelling/Churn_Modelling.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e856661-f551-486d-82f4-911df7ce398e",
   "metadata": {
    "deletable": false,
    "id": "9e856661-f551-486d-82f4-911df7ce398e",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf41430411080c636ff3b6f688c114c6",
     "grade": false,
     "grade_id": "cell-586d73a01f237796",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d4287-b263-401d-86f9-cf3f6f4704d5",
   "metadata": {
    "id": "eb4d4287-b263-401d-86f9-cf3f6f4704d5"
   },
   "source": [
    "# Step 3 Use Standard Scaler(X_scaled) and split the data into training and testing (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e69a39c-14d8-4566-bffb-6ba103ecd082",
   "metadata": {
    "id": "3e69a39c-14d8-4566-bffb-6ba103ecd082"
   },
   "source": [
    "In this task, you will continue preparing the data for training a churn prediction model. After loading and preprocessing the dataset, the next steps involve scaling the features and splitting the data into training and testing sets. These steps are essential to ensure that your machine learning model performs well and can generalize to unseen data.\n",
    "\n",
    "Task:\n",
    "Scale the Features:\n",
    "\n",
    "Use the StandardScaler to scale the features (X) that you prepared in the previous task.\n",
    "Store the scaled features in a variable called X_scaled.\n",
    "Split the Data:\n",
    "\n",
    "Use the train_test_split function from the sklearn.model_selection module to split the scaled data (X_scaled) and the target variable (y) into training and testing sets.\n",
    "Assign 80% of the data to the training set and 20% to the testing set.\n",
    "Use a random seed (random_state=42) to ensure reproducibility.\n",
    "The resulting variables should be X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d60f9-05c4-4c4f-9e37-8721633fcc2d",
   "metadata": {
    "deletable": false,
    "id": "870d60f9-05c4-4c4f-9e37-8721633fcc2d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7dd13c0214b9506cbee38a83728d3595",
     "grade": false,
     "grade_id": "cell-0a37d660d087da78",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a93d5a-d976-4572-85dc-5da8ccf811af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c4a93d5a-d976-4572-85dc-5da8ccf811af",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "432e628edc256c42c75fe78ded48d63c",
     "grade": false,
     "grade_id": "cell-7c3990d8ac79f35d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]  # Number of input features\n",
    "hidden_size = 10  # Number of neurons in the hidden layer\n",
    "output_size = 1  # Binary classification (1 output node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a534b87-7e35-456d-990e-f89a77cbc818",
   "metadata": {
    "id": "8a534b87-7e35-456d-990e-f89a77cbc818"
   },
   "source": [
    "# Step 3 define a function (initialize_parameters) to initialize weights(w1,w2) using rand and biases (b1,b2) using zeros"
   ]
  },
  {
   "cell_type": "raw",
   "id": "338739c6-56bb-4eb0-972b-b28b28914a9d",
   "metadata": {
    "id": "338739c6-56bb-4eb0-972b-b28b28914a9d"
   },
   "source": [
    "In this task, you will implement a function to initialize the parameters of a simple neural network. Proper initialization of the network's parameters is crucial for training effective machine learning models. This initialization includes the weights and biases of the network layers."
   ]
  },
  {
   "cell_type": "raw",
   "id": "48768fa4-e2d2-4375-bddd-67b47f071fb8",
   "metadata": {
    "id": "48768fa4-e2d2-4375-bddd-67b47f071fb8"
   },
   "source": [
    "Function Signature:\n",
    "\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    # Your code here\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20fa1bb3-76fc-4f05-843e-544769fb4fc2",
   "metadata": {
    "id": "20fa1bb3-76fc-4f05-843e-544769fb4fc2"
   },
   "source": [
    "Parameters:\n",
    "input_size: An integer representing the number of input features for the network.\n",
    "hidden_size: An integer representing the number of neurons in the hidden layer.\n",
    "output_size: An integer representing the number of output neurons (i.e., the number of classes or regression outputs).\n",
    "\n",
    "Expected Outputs:\n",
    "W1: A NumPy array of shape (input_size, hidden_size) representing the weights of the layer connecting the input to the hidden layer. Initialize these weights with small random values scaled by 0.01.\n",
    "b1: A NumPy array of shape (1, hidden_size) representing the biases of the hidden layer. Initialize these biases to zero.\n",
    "W2: A NumPy array of shape (hidden_size, output_size) representing the weights of the layer connecting the hidden layer to the output layer. Initialize these weights with small random values scaled by 0.01.\n",
    "b2: A NumPy array of shape (1, output_size) representing the biases of the output layer. Initialize these biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e21e3-fc3a-4e60-b6f2-2808d32e809e",
   "metadata": {
    "deletable": false,
    "id": "d79e21e3-fc3a-4e60-b6f2-2808d32e809e",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ead8d1e97e24328bff9aa79297202bd0",
     "grade": false,
     "grade_id": "cell-3ded5d60e9f5d319",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b18020-b284-48bd-be62-cb2dc9786c31",
   "metadata": {
    "id": "f4b18020-b284-48bd-be62-cb2dc9786c31"
   },
   "source": [
    "# Test case 1: Check initialization of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a7a0d-79fd-490c-b3a2-d17861f492d7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "113a7a0d-79fd-490c-b3a2-d17861f492d7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cdf4adf249e607907f7cf90e4f29ae0",
     "grade": true,
     "grade_id": "cell-bedb71753b87c909",
     "locked": true,
     "points": 100,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "5d9e3551-e025-4693-e898-9cd14976157e",
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
